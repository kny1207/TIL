#### day14_데이터 분석 2

* *판다스: 표 형식의 데이터나 다양한 형태의 데이터 다루는 데 초점*
* *넘파이: 단일 산술 배열 데이터 다루는데 특화*

- 판다스, 넘파이 공부법
    - 두 사이트에서 다운받은 pdf로 공부하면 좋아, 파이썬 만든 사람이 쓴 설명서
        - https://pandas.pydata.org/
        - https://numpy.org/doc/
    
- Anaconda > spider: 파이참같은 통합개발환경, 다양한 기능
    - 주피터 대신 스파이더 쓰는 사람도 있어
    - 강사님: 스파이더보다 파이참이 편리

- Anaconda 수행 환경
     - localhost: 내 컴퓨터라고 이해하면 된다
     - 8888: 외부 인터넷 사이트 서버들과 통신 주고받는 통로(=포트번호)

```python
import pandas as pd  
import numpy as np

# wraning 메세지 무시하기 위한 구문
import warnings
warnings.filterwarnings(action='ignore')
```



##### 판다스에서 데이터 읽어들이는 작업

* clipboard: 복사해 놓은 것 저장해놓는 - ctrl+c한 것
* pickle: 객체 자체, 객체 자체를 저장할 수도 있고 읽을 수도 있다 
  * 바이너리 형태(0101)로 저장 -> 속도 빠름
* table

```python
pd.read_csv('test_text.txt',sep='|')
# 디폴트 행 인덱스: 0번 ~


# 행 인덱스 디폴트값 아닌 ID값으로 지정하기
pd.read_csv('test_text.txt',sep='|', index_col='ID')
pd.read_csv('test_text.txt',sep='|', index_col=0) 
# index_col에 번호 지정해서 원하는 열로 지정 가능. age,lastname도 지정 가능


# 열인덱스 이름 존재하지 않는 텍스트 파일 불러오기
pd.read_csv('test_text_without_name.txt',sep='|', index_col=0) # ==> 1 KIM 25가 열인덱스(header)로
"""
header: 옵션주지 않으면 header=있음 으로 디폴트 설정되어 있음
header=None으로 지정해주면 0,1,2로 자동으로 들어가짐
"""
pd.read_csv('test_text_without_name.txt', header=None, sep='|', index_col=0) 
```

* skiprows: 줄 건너뛸 때 사용

  * skiprows=2: 연속적으로 여러 줄 건너뛸 경우 

    -> header=None 안해주면 header줄 사라지고 처음 줄이 header로

  * skiprows=[1,3] : 비연속적으로 여러 줄을 건너뛸 경우

```python
pd.read_csv('test_text.txt',sep='|', skiprows=2)
pd.read_csv('test_text.txt',sep='|', skiprows=[1,3])

# nrows로 줄 불러오기
# 3줄만 불러오기
data=pd.read_csv('test_text.txt',sep='|', nrows=3)
data.info() 
```

* 결측값(na==	NaN(Not a number)): 값이 누락되어 있는 값
* 결측값 데이터 어떻게 할지 결정해야, 무조건 제거하는 것이 좋진 않음.
  데이터 충분하지 않을 때는 결측값을 잘 대체해줘야 함.
* info(): R의 str함수와 같은 용도 
  - 결측값 확인 가능(non-null)
  - 데이터 타입 확인 가능 -> 파이썬에선 object==string
  - 데이터 크기 확인 가능

```python
data=pd.read_csv('test_text_na.txt',sep='|')
# 결측값 확인하기
data.info()
data
=> AGE 5 non-null object: 숫자에 문자가 섞여있어서 object로 나온 것

    
# 없음, 모름 결측값 컴퓨터에게 결측값이라는 것 이해시키기
data=pd.read_csv('test_text_na.txt',sep='|',na_values=["없음","모름"])
data.info()
data
```

* 데이터 타입 지정
* 데이터 타입은 판다스로 인해서 지정되는데 내가 원하는 대로 데이터 타입 지정 가능
  * age를 문자나 실수형으로 읽으라고 수동으로 지정 가능

```python
# age를 문자형으로 지정해주기: dtype사용
data=pd.read_csv('test_text_na.txt',sep='|', dtype={'ID':int,'LAST_NAME':str,'AGE':str})
data.info()
data
```





##### 판다스에서 데이터 저장하는 방법

* 데이터프레임으로 저장된 데이터를 파일로 저장: to_csv함수 사용
* DataFrame.to_csv함수: 데이터프레임을 csv로 저장할때 사용하는 함수

```python
import pandas as pd   # pd.DataFrame(), pandas.DataFrame()
import numpy as np
from pandas import DataFrame # 판다스 안에 있는 DataFrame만 가지고 오는 것 ==> DataFrame()
from pandas import * 
==> 판다스 안에 있는 모든걸 다 가지고 와라: * 안에는 DataFrame 포함 -> DataFrame()

DataFrame.to_csv() 
==> 판다스 안에 DataFrame을 가지고 와야 사용 가능
pd.DataFrame()
DataFrame()
pandas.DataFrame()
```

* **데이터프레임 생성**
  * 딕셔너리로 만들기, 보통 딕셔너리를 많이 사용
  * array로 만들기도 가능 = array를 데이터로 삼아도 된다

```python
from pandas import DataFrame

# 딕셔너리 데이터로 데이터프레임 생성하기
df=DataFrame(data={
    'id':['a1','a2','a3','a4','a5'],
    'x1':[1,2,3,4,5],
    'x2':[1.1,2.2,3.3,4.4,5.5]
}, index=['a','b','c','d','e']) 
# df에 index=['a','b','c','d','e']로 추가해서 index 직접 지정해주기
df 
==> key가 열인덱스로, 행인덱스는 자동으로 0,1,2로 부여 -> index 지정 가능
# df에는 data와 index로 인수 2개. ,로 구분해주는 인수. data가 생략되도 가능.
```

* 새로운 행 추가, 삭제: reindex() 사용
  * index로 주어진 것과 동일한 것들만 출력
  * 새로운 행 추가
    *  결측값으로 구성된 새로운 행 추가(default가 NaN으로 채워짐)

```python
from pandas import DataFrame

df=DataFrame({
    'id':['a1','a2','a3','a4','a5'],
    'x1':[1,2,3,4,5],
    'x2':[1.1,2.2,3.3,4.4,5.5]
}, index=['a','b','c','d','e']) 
df

# 새로운 행 추가: reindex() 사용
# 결측값으로 구성된 새로운 행 추가(default가 NaN으로 채워짐)
df2=df.reindex(['a','b','c','d','e','f'])
df2

# index가 동일한 것들만출력
df3=df.reindex(['a','k','c','e','f'])
df3 # b,d는 출력 x, k는 결측값으로 추가됨
```

* 파일로 저장하기
  * to_csv

```python
# to_csv로 파일저장하기

df2.to_csv("df2.csv") 
==> 파일 확인하면 none값이 빈칸으로 나옴

df2.to_csv("df3.csv", sep="$")
==> 칸 나누어지지 않아 한 칸에 다 들어감

df2.to_csv("df4.csv",na_rep='NaN') # na_rep= : na 표시하겠냐는 의미
==> 결측값 NaN으로 표시됨

df2.to_csv("df4.csv",na_rep='NaN',header=None)
==> header 사라짐

df2.to_csv("df4.csv",na_rep='NaN', float_format="%.2f")
==> 메모장으로 열면 소수 두번째 자리까지 확인 가능

df2.to_csv("df5.csv",na_rep='NaN',columns=['id','x2'])
==> 지정안된 컬럼(열) x1은 없이 저장됨.

df2.to_csv("df5.csv",na_rep='NaN',columns=['id','x2'], index=False)
==> index=False로 행 없애기 가능
```

* 데이터프레임 만들고 특정 column 확인하기

```python
# reshape(): 차원바꿀 수 있는 함수

np.arange(8).reshape(2,4) 
==> reshape으로 2행 4열의 2차원 array로 

np.arange(8).reshape(2,2,2)  
==> 3차원 array

df(np.arange(8).reshape(4,2)) 
# 데이터프레임 딕셔너리말고 array로도 만들 수 있다 == df(data=np.arange(8).reshape(4,2))
==> 4행 2열 array dataframe으로 만들어줌
```

```python
df(data=np.arange(8).reshape(4,2), columns=['col0','col1'])
==> columns로 column이름 지정해주기 가능

df(data=np.arange(8).reshape(4,2), columns=['col0','col1'],index=['row0','row1','row2','row3'])
==> index로 row(열)이름 지정 가능

df1=df(data=np.arange(8).reshape(4,2), columns=['col0','col1'], index=['row0','row1','row2','row3'])
type(df1) 
==> pandas.core.frame.DataFrame
```

```python
# transpose matrix
# transpose matrix(=전치 행렬): 행과 열의 위치 바꿔줌
df1.T
==> df1은 바뀌지 않아, df1을 아예 바꾸고 싶으면 assign해줘야 함.


 # axis(축,단수), axes(복수)
 df1.axes # 행과 열에 대한 index 확인 가능
==> [Index(['row0', 'row1', 'row2', 'row3'], dtype='object'),
 Index(['col0', 'col1'], dtype='object')]


# dtypes
df1.dtypes 
==> 행과 열의 데이터 타입 정보 알 수 있음

## dtypes 보다 info() 쓰면 더 많은 정보 알 수 있어, info 많이 사용
df1.info()

# shape: 데이터 어떻게 생겼는지 확인 가능
df1.shape
==> (4,2): 행,열의 개수 튜플로 나옴 -> 8개의 데이터로 있는 것
df1.shape[0]
==> 4: 행의 개수로 즉 column(=변수) 몇 개 있는지 알 수 있음
df1.shape[1]
==> 2: 변수에 있는 데이터 개수 확인 가능
 
# size: 데이터 크기 알 수 있음
 df1.size
 
# 데이터 확인하기
 df1.values
```

* 데이터프레임 생성

```python
df=DataFrame({"cls_1":['a','a','b','b','c'],
               "v1":np.arange(5),
               "v2":np.random.randn(5)},
               index=['r0','r1','r2','r3','r4'])
```



##### 원하는 데이터 추출하기

* ix : 특정 열 데이터 참조
  * 행 위치(정수)로 지정 가능
  * 행 인덱스 이름으로 지정 가능

```python
df.index # 행 인덱스 확인 가능
==> Index(['r0', 'r1', 'r2', 'r3', 'r4'], dtype='object')


# wraning 메세지 무시하기 위한 구문
import warnings
warnings.filterwarnings(action='ignore')


df.ix
# ix는 행 단위 indexing할 때, 행 위치(정수)와 행 인덱스 이름을 모두 사용할 수 있다.
df.ix[2]  # 행 위치(0번부터 시작)
=> 2번 인덱스, 3번째줄 내용 추출
df.ix['r2'] # 행 인덱스 이름 
=> 2번 인덱스, 3번째줄 내용 추출 

# 인덱스 3번부터 마지막까지 추출
df.ix[3:5]
df.ix[3:]
df.ix['r3':]
```

* head: 위에 부분 일부 추출
* tail: 뒤에 부분 일부 추출

```py
df.head(3)
df.tail(3)
```

* 특정 column 데이터 가져오기
  * 참조하고자 하는 열 1개 이상일 때(2개부터) 대괄호 기호 2개 써줘야 함
  * 열 찹조할 때 대괄호 기호 2개 사용하는 것이 좋아
    * 열 하나 참조할 때도 대괄호 1개와 2개 차이: 2개써야 데이터프레임, 하나쓰면 시리즈 타입

```python
# 특정 열 추출

# cls_1 부분만 가져오기
df['cls_1'] # []에 컬럼 이름 지정
df.cls_1 # .찍고 컬럼이름 지정 

# 한개 이상의 열 참조
df1['cls_1','v1']
==> KeyError
# 대괄호 두개 써줘야 함
df[['cls_1','v1']]

# 열 찹조할 때 대괄호 기호 2개 사용하는 것이 좋아
# 열 하나 참조할 때도 대괄호 1개와 2개 차이: 2개써야 데이터프레임, 하나쓰면 시리즈 타입
type(df[['cls_1']]) # DataFrame
type(df['cls_1']) # Series
```

* 데이터 프레임 수정(삭제, 추가)
  * reindex 사용
    * fill_value=: NaN을 특정 값으로 채움

```python
df=DataFrame({"cls_1":['a','a','b','b','c'], "v1":np.arange(5), "v2":np.random.randn(5)},index=['r0','r1','r2','r3','r4'])

# 행인덱스: r3,r4 제거, r5,r6 추가
df.reindex(['r0','r1','r2','r5','r6'])

# fill_value 사용해서 NaN값 대체 가능
df.reindex(['r0','r1','r2','r5','r6'],fill_value=0)
df.reindex(['r0','r1','r2','r5','r6'],fill_value='missing')
df.reindex(['r0','r1','r2','r5','r6'],fill_value='NA')
```



##### 시계열 데이터

* 주기적으로 기록되어지는 데이터
  * DataFrame에서 index를 만들때 **date_range** 함수 사용
  * freq 옵션으로 설정 가능

```python
pd.date_range("1/7/2020",periods=5)
==> DatetimeIndex(['2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10','2020-01-11'],dtype='datetime64[ns]', freq='D')
# 데이터 첫번째 인수가 리스트(날짜데이터 생성)
# 데이터 타입은 datetime(=날짜데이터) ns(=nano second:1억분의 1초)
# freq='D': day말하는 것

# 월단위로 데이터 생성
pd.date_range("1/7/2020",periods=5,freq='M')
==> DatetimeIndex(['2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30','2020-05-31'],dtype='datetime64[ns]', freq='M')

# 년단위로 데이터 생성
pd.date_range("1/7/2020",periods=5,freq='Y')

# 시간단위로 데이터 생성
pd.date_range("1/7/2020",periods=5,freq='H')

# 날짜단위로 데이터 생성
pd.date_range("1/7/2020",periods=5,freq='D')
```

* 날짜 객체(date_idx)를 index로 넣어주기
  * reindex + fill_value로 결측값 채우기
    * method='ffill' 사용해서 결측치 채우기
    * method='bfill' 사용해서

```python
# 날짜 객체 만들기
date_idx=pd.date_range("1/7/2020",periods=5,freq='D')

# 데이터프레임 생성
df2=pd.DataFrame({"c1":[5,3,7,6,4]})

# 날짜 객체(date_idx)를 index로 데이터프레임에 넣어주기
df2=pd.DataFrame({"c1":[5,3,7,6,4]},index=date_idx)
df2

# 날짜 객체가 데이터프레임 값과 안 맞으면 에러
date_idx2=pd.date_range("1/1/2020",periods=20, freq="D")
df3=pd.DataFrame({"c1":[5,3,7,6,4]},index=date_idx2)
df3 
# ==>  Shape of passed values is (5, 1), indices imply (20, 1)


# reindex 사용 + fill_value로 결측값 채우기
df2=pd.DataFrame({"c1":[5,3,7,6,4]},index=date_idx)
df2.reindex(date_idx2) # fill_value=0
==> df2에 있는 값 제외하곤 NaN으로 채워져서 출력

# method='ffill'사용해서 결측치 채우기(=데이터방향으로)
df2.reindex(date_idx2,method='ffill')

# method='bfill' 사용해서 결측치 채우기(=역방향으로 결측치 채워짐)
df2.reindex(date_idx2, method='bfill')
```



##### 캘리포니아 대학 인공지능 연구실에서 오픈해 놓은 데이터 셋

https://archive.ics.uci.edu/ml/datasets.php

* classification: 분류(예, 아니오)
* Regression: 회귀분석
* clustering: 비교사학습(교사=답) Kmeans 알고리즘이 대표적
  * 데이터 라벨(표식)이 없는 데이터들 묶어서 그룹화 시키는 것
  * Zoo data에서 어떤 동물인지 알 수 없는 데이터라면 clustering(=비교사학습)으로 그룹화 해준다.

* Zoo Data Set
  * 동물에 대한 특성과 답 있는 데이터 == 교사학습(답 있음)
    * 어떤 동물 나타내는지 알 수 있는 데이터
  * Instances: 데이터 건수
  * Number of Attributes: 속성
    * attribute 1: 동물이름, 동물 특성 아니므로 분석에 의미 x 데이터
    * attribute 18: 동물 분류해준 데이터로 분석에 의미 x 데이터
  * 다운로드 > .data로 된 데이터 다운





