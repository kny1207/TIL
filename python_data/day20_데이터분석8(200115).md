### day20_데이터분석8(200115)



```python
import pandas as pd
import numpy as np
```



#### 정렬

##### 데이터프레임 정렬

* sort_values()

````python
help(pd.DataFrame.sort_values) 
==> example도 밑에 나와있음

df = pd.DataFrame({'seq':[10,30,np.nan],'name':['park','kem','choi'],'age':[25,35,22]})

# sort_values()
df.sort_values(by='seq')
# ascending 옵션
df.sort_values(by='seq',ascending=False)
# inplace=True: 변경된채로 df에도 적용, 출력
df.sort_values(by='seq',ascending=False, inplace=True) 
==> df에 내부적으로 변경상황이 적용
# na_position='first': NaN값을 맨 앞으로 오게 하는 옵션
df.sort_values(by='seq',ascending=False, inplace=True, na_position='first')
````



##### 튜플정렬

* sorted()

  sorted(튜플변수, 정렬기준)

```python
tup=[(1,'kim',25),(3,'lee',20),(2,'park',15)]
tup

sorted(tup)
# sorted(튜플변수, 정렬기준)
# lambda함수 정의하게 되면, key가 lambda이면 p에 튜플이 하나씩 전달되어진다. 
sorted(tup,key=lambda p:p[0]) 
==> 0번째 인수인 숫자를 기준으로 정렬되어짐
sorted(tup,key=lambda p:p[1]) 
==> 1번째 인수인 성을 기준으로 정렬되어짐
sorted(tup,key=lambda p:p[2])
==> 2번째 인수인 나이를 기준으로 정렬되어짐

# reverse 옵션: 역순으로 내림차순 정렬
sorted(tup,key=lambda p:p[2], reverse=True)
==> 25 > 20 > 15로 정렬
```



##### 리스트 정렬

* sorted(list)
  * sorted(list)는 list에는 영향미치지 X

```python
myList=[0,1,2,5,4,7,8,6,3]
sorted(myList) 
# revers=True 옵션: 내림차순으로
sorted(myList, reverse=True) 
myList # sorted한 후에 myList 출력하면 변경 안되어 있음
```

* list.sort()
  * list.sort()는 정렬되어진 결과를 list에 저장

```python
myList.sort() 
# 원래 데이터 아닌 sort()로 정렬되어진 변경 결과가 myList에 저장됨
myList
```





#### 데이터프레임 생성, 수정, 삭제

**데이터프레임 생성, 수정, 삭제가 데이터 분석의 기본 작업**

##### series

```python
# 시리즈 생성
s1=pd.Series([3,1,4,2,5])
s1

# 참조
s1[2] # 4
s1[0:3] # 3 1 4 
# 열 평균값보다 큰 데이터만 추출 ==> 불린참조! 자주 쓰니까 연습 많이 하기!!
s1[s1>s1.mean()]
# 2개 이상 참조: 대괄호 2개로 묶어줘야
s1[[4,2]]
```

* index에 label할당한 sereis

```python
# index에 label할당한 sereis 생성
s=pd.Series([10,20,30,40,50], index=['a','b','c','d','e'])
s

# index에 label있는 series 참조
s['a']
# 2개 이상의 값 참조
s[['a','c','e']]
# series.get() 사용해서도 참조 가능
s.get(['a','b','c'])

# 특정 라벨 인덱스에 저장된 값 변경하기
s['c']=300
s

# for문 활용해 series에 특정값 있는지 확인할 수도 있음
'c' in s # sereis s안에 'c' 라벨 인덱스가 있습니까?  존재하므로 True나옴
'z' in s # False, 결과가 boolean으로 나옴
```



##### DataFrame

```python
# 데이터프레임 생성
df=pd.DataFrame({'c1':[1,2,3],'c2':[4,5,6],'c3':[7,8,np.nan]},index=['r1','r2','r3'])

# 데이터프레임 정보 확인
df.info() # R언어 str()와 같은 역할, dataframe 정보 전달해줌
df.index # index 확인 가능
df.columns # columns 확인 가능
```

* 재구성

  > 데이터프레임 추출 > 새 데이터프레임 생성

  > 데이터프레임 열지정
  >
  > 2개 이상 열 지정하려면 대괄호 2개로 묶어줘야 함: df[['c1','c2]]

```python
df1 = pd.DataFrame(df) 
# 데이터프레임 df를 넣어주면, df와 같은 데이터프레임이 하나 더 생기게 됨
df1 
==> df와 같은 데이터프레임

# df index 'r1','r3'만 가지는 df 만들어주기
df13 = pd.DataFrame(df, index=['r1','r3'])
df13

# df c1과 c3열 추출 => dfc13이라는 데이터프레임 만들기
dfc13 = pd.DataFrame(df, columns=['c1','c3'])
dfc13

# r3, r1행 c3, c1열을 추출 => rfrc13 데이터프레임 만들기
# 추출 순서에 따라 정렬도 달라짐
rfrc13 = pd.DataFrame(df, index=['r3','r1'], columns=['c3','c1'])
rfrc13
```

* 데이터프레임 새로운 열 추가
  * df['컬럼명'] = 데이터
  * df.assign() 사용

```python
# df['컬럼명'] = 데이터

# 새로운 열 추가하기
df['c4']=df['c1']+df['c2']

# 함수 사용해서 새로운 열 추가
df = df.assign(c5=df['c1']*df['c2'])
# lambda함수로도 표현 가능
df = df.assign(c6=lambda x:x.c1-x.c2) # x에는 dataframe df가 전달됨
df
```

* 데이터프레임 데이터 삭제

  > df.drop()
  >
  > column(열)제거할 땐 axis=1로 줘야 함
  >
  > row(행) 제거할 땐 axis=0, default가 axis=0이라 생략 가능

```python
# c4열 제거
df.drop(['c4'], axis=1) # column제거할 땐 axis=1로 줘야 함

# c2, c4, c5 열 제거
df.drop(['c2','c4','c5'],axis=1)

# r2행 제거
df.drop(['r2'])
df.drop(['r2'],axis=0) # default axis=0
```

> del명령
>
> column만 제거 가능, 행 제거 안됨

```python
# 'c4' column(열) 제거
del df['c4']
df
```

* 특정 행 추출

```python
# 조건에 만족하는 행 추출
df['c1']<=2 
==> 조건에 따라 boolean 결과 출력

# 위의 조건을 df에 넣어줘서 데이터프레임 추출 가능
df[df['c1']<=2] # True(=조건에 만족)에 해당하는 행 추출

# 추출하고 싶은 인덱스 변수에 지정해주고 추출
col_sel=['c1','c3']
df[col_sel]
```





#### Numpy

```python
# array 생성

# 1
arr1 = np.array([1,2,3,4])
arr1

# array 속성 확인
arr1.shape # (4,)
arr1.dtype # dtype('int32')


# 2: list만들고 리스트 인수로 넣어줘서 array 생성하기: 1차원 리스트의 경우
mylist=[5,6,7,8]
arr2 = np.array(mylist)

#3: asarray: mylist를 array로 변환
mylist = np.asarray(mylist)
type(mylist) # numpy.ndarray
```

* asfarray: 유효성 검사

```python
# 유효성 검사
# asfarray: array 타입 float으로 변환하기
np.asfarray(mylist)

# asarray_chkfinite: 유효성 검사 체크한 후 배열로 변환하고 싶을 때 사용하는 함수
# 배열(array)로 변환시 무한수(inf), 결측값(NaN)이 있는지 확인
mylist
np.asarray_chkfinite(mylist)
# ==> 결측값 없으면 array로 변환됨

# 결측값 있는 경우
# mylist=[5,6,7,np.nan]
# np.asarray_chkfinite(mylist)
# ==> 결측값 있는 경우 에러

# 무한수(np.inf) 있는 경우
mylist=[5,6,7,np.inf]
np.asarray_chkfinite(mylist)
```

* 1차원 배열 초기화

```python
# zeros()
np.zeros(5) # array([0., 0., 0., 0., 0.])
# ones()
np.ones(10) # array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])

# 벡터화 연산
np.ones(5)*2 # array([2., 2., 2., 2., 2.]) 
# empty
np.empty(10) # 1로 초기화
```

* 다차원 배열 초기화

```python
# 튜플로 나타내기 가능 > 다차원배열

# 다차원 배열 초기화
np.zeros((2,5))
np.ones((2,5))

# reshape()

arr = np.arange(12)
arr # array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

# reshape으로 배열 바꾸기
arr = arr.reshape(3,4)
arr

# arr(3행 4열) 0으로 초기화
# np.zeros_like 함수 사용 
np.zeros_like(arr)
np.ones_like(arr)
```

* 배열 바꾸기

```python
# reshape()

arr = np.arange(12)
arr # array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

# reshape으로 배열 바꾸기
arr = arr.reshape(3,4)
arr

# arr(3행 4열) 0으로 초기화
# np.zeros_like 함수 사용 
np.zeros_like(arr)
np.ones_like(arr)
```

* 항등행렬

```python
# 단위(항등) 행렬: 대각요소 1, 나머지 요소(성분) 0인 행렬
# np.eye(), np.identity() 사용

np.eye(3) # 3행 3렬의 정방행렬 만들어짐

np.identity(3)
```

* 난수 생성

```python
# 난수생성(np.random)

# np.random.normal: 정규분포로부터 개수가 1인 무작위 샘플 추출
np.random.normal() 

# size 옵션
np.random.normal(size=5) 

# seed: 난수값 동일하게 만들고자 할 때
np.random.seed(seed=777)
np.random.normal(size=5)  # 1차원
np.random.normal(size=(2,5)) # 2차원(2행 5열의 array 만들어짐)
```



##### Numpy 연산

> numpy 데이터타입: boolean, int, float, string
>
> 숫자형(=boolean, int, float)/문자형(string)
> 데이터분석에선 대부분 float, int type을 다루게 될 것

* 넘파이 함수 이용해서 데이터 형태 타입 지정, 변경

```python
# dtype: 데이터타입 확인
x = np.array([3,2,4,5])
x.dtype # dtype('int32')


x = np.array([3.1,2.5,4.1, 5.2])
x.dtype # dtype('float64')

# 데이터타입 지정해주기 :dtype=np.int32 => 실제로 float data가 int로 변함
x = np.array([3.1,2.5,4.1, 5.2], dtype=np.int32)
x.dtype
x # array([3, 2, 4, 5])

# array 만드는 방법 다양함
x=np.int32([1,5,2,4])
x # array([1, 5, 2, 4])
```

* 데이터 타입 변환

```python
# 구문형식: 데이터.astype(변환타입)

x=np.int32([1,5,2,4])
x.astype(np.float64) # array([1., 5., 2., 4.])
x.dtype # dtype('int32')

# 데이터 타입 변환하기
# float 형태 데이터만들기
x = np.float64([3,2,1])
# float > int: astype 사용
x.astype(np.int64) # array([3, 2, 1], dtype=int64)
# int > sting
x = x.astype(np.string_)
x # array([b'3.0', b'2.0', b'1.0'], dtype='|S32')
x.dtype # dtype('S32')
```



##### 벡터화 연산

> 주의점
>
> : 두 배열의 차원이 같아야 연산 가능, 두 배열의 차원 다를 경우 동일하게 만들어줘야 함. 차원이 다르면 넘파이가 broadcasting을 통해 차원을 동일하게 만들어줌

* 벡터화 연산속도

```python
# 벡터화 연산과 일반 연산 비교: 벡터화연산 속도가 훨씬 빠름
a = np.arange(1000000)
%timeit a+1 # 2.38 ms
%timeit [i+1 for i in a] # 409 ms
```

* 벡터화 연산

```python
x = np.array([1.,1.,2.,2.])
y = np.array([1.,2.,3.,4.])


# 벡터화 연산을 통해 한번에 연산 가능한 경우

# y(=배열) + 1(=스칼라 ): for문을 돌려야 가능한 연산이 넘파이 벡터화 연산으로 한번에 가능
y + 1
y/2
y//2
y%2
y ** 2

# 같은 배열끼리 연산
# element wise product: 같은 요소간 곱셈/ matrix multiply: 행렬의 곱셈
# element wise == 요소끼리
x+y  # element wise sum
x-y
x/y
x%y
x**y
```

* 연산결과 묻는 함수

```python
# np.equal(): 연산 결과 같은지 묻는 함수
np.equal(x,y) # array([ True, False, False, False]): 요소 4개이므로 4개의 답 
np.not_equal(x,y) # array([False,  True,  True,  True])

# np.greater: 더 큰지 묻는 함수
np.greater(x,y) # x>y
np.greater_equal(x,y) # x>=y

# np.less
np.less(x,y) # x<y
np.less_equal(x,y) # x<=y


# 배열 전체 비교
np.array_equal(x,y) # False
np.array_equal(x,x) # True

# 배열 간 할당연산(*=,/=,**=)
x+=y # array([2., 3., 5., 6.])
```

* 논리 연산

```python
x = np.array([1,1,0,0])
y = np.array([1,0,1,0])

# 논리 and 연산: 연산되어지는 두 대상이 모두 1일때만 참, 나머지는 거짓
np.logical_and(x,y) # array([ True, False, False, False])
# 논리 or 연산: 연산되어지는 두 대상 중 하나라도 1이면 참, 나머지는 거짓
np.logical_or(x,y) # array([ True,  True,  True, False])
np.logical_xor(x,y) # array([False,  True,  True, False])
```

* 소속 여부 확인 

```python
# 소속 여부 확인 연산: in, not in
# 객체 in 배열: 배열에 객체가 있으면 True
a="x"
b=np.array(["x","y"])
a in b # True
"z" not in b # True
```

##### broadcasting

* 배열의 크기가 다른 경우 연산하기

```python
# 요소의 개수가 다른 경우
x = np.array([1.,1.,2.,2.])
y = np.arange(5)
x+y 
==> ValueError: operands could not be broadcast together with shapes (4,) (5,)
# 두 배열 간 차원이 같아야 연산 가능
```

* broadcast

```python
# broadcast
ar = np.array([1,2,3,4])
ar.shape # (4,): 1차원 벡터
ar+1 # broadcasting: 스칼라 1 => 1 1 1 1로 확장 => [2 3 4 5]
```

* 데이터프레임과 broadcast

```python
df = pd.DataFrame({'x1':[1,2,3], 'x2':[4,5,6]})
df
df+1 # ==> 브로드캐스팅 가능
"""
1이 3행2열로 brodacasting되어져 연산 가능
1 1
1 1
1 1
"""
```

```python
ar = np.arange(12).reshape(4,3)
ar
ar2 = np.array([1,2,3])
ar2
ar+ar2 # 연산 가능
"""
broadcasting
[1,2,3]
==>
[[1,2,3]
 [1,2,3]
 [1,2,3]
 [1,2,3]]
"""

ar = np.arange(12).reshape(4,3)
print(ar)

ar2 = np.array([1,2,3,4])
print(ar2.shape) # (4,)
# ar+ar2 
# ValueError: operands could not be broadcast together with shapes (4,3) (4,) 

ar2 = np.array([1,2,3,4]).reshape(4,1)
ar2 # (4,1)
ar+ar2  # 연산 가능
```



#### 이항분포

>모집단 - 확률분포  => 분위수에 대한 확률 계산 가능, 특정 확률에 해당되는 분위수 계산 가능
>
>난수발생: 확률분포를 이용해서 난수를 발생
>
>
>확률분포: 연속형 확률 분포, 이산형 확률 분포
>- 연속형 확률 분포: 정규분포, t분포, f분포, 균등분포, 카이제곱, 감마분포
>- 이산형 확률 분포: 이항분포, 포아송, 초기하분포
>



>
>이항분포
>
>성공확률이 p인 베르누이시행을 n번 반복했을 때 성공횟수를 x라고 하면, 
>확률변수 x는 모수 n과 p인 이항분포를 따른다.
>이항분포 = nCx * p의 x승 * (1-p)의 n-x승: 성공확률, 실패확률로 구함
>
>- 순열과 조합의 차이: 중복허용 하냐 안 하냐
>- 순열: 1,2,3 -> 2,3  => 1 == 3 * 2 * 1 = 6가지
>       123 132 213 231 312 321
>
>베르누이 시행: 각 시행마다 성공/실패 경우의 수만 나오는 시험

* binomial()

```python
# 이항분포 함수 사용
np.random.binomial(n=1, p=.5, size=20)
```





#### Titanic EDA

> EDA(Exploratory data analysis): 탐색적 데이터 분석 
> = 내가 직접 데이터를 들여다보면서 데이터 확인, 분석하는 것으로 지금부터 하는 작업은 전부 EDA작업이라고 생각하면 된다.
>
> EDA 작업은 거의 시각화 작업, 수치보다 눈으로 직접 확인하는 것이 더 좋음

* titanic 데이터로 데이터분석

```python
train = pd.read_csv('data/train.csv')

# 데이터 확인
train.head(80)
train.shape # (891, 12)
train.info()

# null값 확인하는 작업
train.isnull().sum(axis=0) # column별 null 개수 세기
```

* 생존자 > 성별 시각화로 확인

```python
# 참조: 생존자만
train['Survived']==1 # 생존 ==> True값으로 출력
train[train['Survived']==1] # ==> 생존한 사람만 출력됨

# 생존자 성별 알아보기
train[train['Survived']==1]['Sex'] # 생존자 > 성별 확인 가능

# 성별에 따른 생존자 확인: value_counts() 사용
train[train['Survived']==1]['Sex'].value_counts()
survived = train[train['Survived']==1]['Sex'].value_counts()
# 사망자 
dead = train[train['Survived']==0]['Sex'].value_counts()

# 데이터타입 확인
type(survived) # pandas.core.series.Series
type(dead) # pandas.core.series.Series

# 데이터프레임으로 구성하기
df = pd.DataFrame([survived, dead])
df.index=['Survived','Dead']

# 시각화해서 확인하기
import matplotlib.pyplot as plt
df.plot(kind='bar')
df.plot(kind='bar',stacked=True, figsize=(10,5))
```

* Pclass별 생존자 확인

```python
survived = train[train['Survived']==1]['Pclass'].value_counts()
dead = train[train['Survived']==0]['Pclass'].value_counts()

# 데이터프레임으로 구성하기
df = pd.DataFrame([survived, dead])
df.index=['Survived','Dead']

# 시각화해서 확인하기
import matplotlib.pyplot as plt
df.plot(kind='bar')
df.plot(kind='bar',stacked=True, figsize=(10,5))
```

* 위의 코드 함수로 정의

```python
# 위의 기능을 함수로 정의해서 편하게 사용하기

# 인수 받아서 그래프로 시각화해주는 함수
def my_chart(feature):
    survived = train[train['Survived']==1][feature].value_counts()
    dead = train[train['Survived']==0][feature].value_counts()
    df = pd.DataFrame([survived, dead])
    df.index=['Survived','Dead']
    df.plot(kind='bar',stacked=True, figsize=(10,5))
```

* 함수 활용하여 간단하게 인수별 그래프 확인 가능

```python
my_chart('Sex')
```

```python
my_chart('Pclass')
```

```python
my_chart('SibSp')
```

```python
my_chart('Embarked')
```

* Name > 호칭만 뽑아내기

> 호칭만 출력 > 정규식 작성: extract 이용
>
> extract: 문자열 추출하는 함수

```python
# ex. Braund, Mr

train['Name']
type(train['Name'])
==> pandas.core.series.Series 
"""
> series엔 문자열 함수 적용 x > str로 변환 후 정규식써서 extract로 호칭 뽑아줘야
train['Name'].str.extract(" ([A-Za-z]+)\.") 

공백 + 영문자 + .으로 끝나는 패턴 뽑아오기: ([A-Za-z]+)로 ()안에 있는 것(=[A-Za-z]+)이 추출대상
"""

# title 열 추가
train['title'] = train['Name'].str.extract(" ([A-Za-z]+)\.") 
train

# value_counts 함수 적용
train['title'].value_counts() # 데이터건수 별 확인 가능
```

* title data 범주화

```python
"""
어제 배운 내용처럼 title data 범주화해주기 가능: mapping 사용
"""
title_mapping={'Mr':0, 'Miss':1, 'Mrs':2,'Master':3}
train['title'].map(title_mapping)
train['title'] = train['title'].map(title_mapping)
train['title'].value_counts()

"""
이름은 생존률에 영향미치지 x, 호칭만 남겨두고 이름컬럼 지우기
"""
train.drop('Name',axis=1) # train data에 반영 x
train.drop('Name',axis=1, inplace=True) # 데이터에 반영
train
```

* 문제

```python
"""
문제
Sex -> male:0, female:1로 매핑해서 데이터에 반영하기
"""
sex_mapping = {'male':0,'female':1}
train['Sex'] = train['Sex'].map(sex_mapping)
train
```

```python
"""
16세이하: 0, 16~26: 1, 26~36: 2, 36~62: 3, 62초과:4
"""

# age 요소 하나하나에 접근해서 바꿔줘야
train['Age']<=16
train[train['Age']<=16]
# train[train['Age']<=16]['Age'] = 0 # warning

# 각 조건 참조해서 데이터 변경해줘야
train.loc[train['Age']<=16,'Age']=0
train.loc[(train['Age']>16) & (train['Age']<=26), 'Age']=1
train.loc[(train['Age']>26) & (train['Age']<=36), 'Age']=2
train.loc[(train['Age']>36) & (train['Age']<=62), 'Age']=3
train.loc[train['Age']>62,'Age']=4
```

