## day24_자전거 데이터 분석2



```python
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
from scipy  import stats
```



#### train, test 데이터 가져오기

```python
# parse_dates=["datetime"] 옵션주기: 날짜형식으로 불러오기
train = pd.read_csv("bike-sharing-demand/train.csv", parse_dates=["datetime"]) 
test = pd.read_csv('bike-sharing-demand/test.csv', parse_dates=["datetime"])

# train data 확인
train.info()
train.head()

# test data 확인
test.shape # (6493, 9)
```



* 데이터 확인

```python
# describe

train.describe()
test.describe

# 결측값 확인
test.isnull().sum() 
# > 결측값 x, windspeed에 0이 너무 많이 들어있는 것이 문제
```





### Feature Engineering

> 데이터 전처리, 파생 변수 생성...
> 파생 변수: 원하는 변수 만드는 것

* 데이터 추출(train)

```python
# 원하는 데이터 추출 
train['datetime']

# 데이터 추출해서 새로운 행 만들기
train['year'] = train['datetime'].dt.year
train['month'] = train['datetime'].dt.month
train['day'] = train['datetime'].dt.day
train['hour'] = train['datetime'].dt.hour
train['minute'] = train['datetime'].dt.minute
train['second'] = train['datetime'].dt.second
# 추가
train['dayofweek'] = train['datetime'].dt.dayofweek
train.shape # (10886, 19)
```

* 데이터 추출(test)

```python
# test data에서도 동일 작업
test['datetime']
test['year'] = test['datetime'].dt.year
test['month'] = test['datetime'].dt.month
test['day'] = test['datetime'].dt.day
test['hour'] = test['datetime'].dt.hour
test['minute'] = test['datetime'].dt.minute
test['second'] = test['datetime'].dt.second
test['dayofweek'] = test['datetime'].dt.dayofweek

test.shape # (6493, 16)
```



#### 시각화

```python
![시각화1](0121_images/시각화1.pngfig, axes = plt.subplots(nrows=2)
fig.set_size_inches(16,8)

# sca(set current axis): 현재 축 설정해주는 함수. plt 이용해서 axes0에 밑에 옵션들 적용하겠다는 것 

# train 시각화
plt.sca(axes[0])
plt.xticks(rotation=30)
sns.countplot(data=train, x='windspeed', ax=axes[0])

# test 시각화
plt.sca(axes[1])
plt.xticks(rotation=50)
sns.countplot(data=test, x='windspeed', ax=axes[1])
```

![시각화1](images/시각화1-1579594405294.png)



#### windspeed 예측

```python
# 풍속이 0인 것과 아닌 것을 구분해서 저장
trainWind0 =  train.loc[train['windspeed']==0]
trainWindNot0 = train.loc[train['windspeed']!=0]
print(trainWind0.shape) # (1313, 19)
print(trainWindNot0.shape) # (9573, 19)
```



##### 랜덤포레스트로 풍속값 예측하기

```python
#### 머신러닝 랜덤포레스트로 풍속 예측

"""
풍속 0이 아닌 값들 모아서 랜덤포레스트로 학슴
> 0인 풍속값들 위의 결과인 예측값으로 대체해서 전처리
"""

# 랜덤포레스트 예측 만들어보기

from sklearn.ensemble import RandomForestClassifier

# 풍속이 0인 값 너무 많아 값이 0인 데이터 예측한 값으로 대체하기
# == data의 windspeed값이 0인 데이터를 랜던포레스트를 이용하여 예측한 값으로 대체
def predict_windspeed(data):
    # 풍속예측에 사용되는 변수(column)
    wCol = ['season','humidity','month','temp','weather','year','atemp']
    
    # 풍속을 0인 것과 아닌 것으로 구분
    dataWind0 = data.loc[data['windspeed']==0]
    dataWindNot0 = data.loc[data['windspeed']!=0]
    
    
    # 랜덤포레스트 분류기 생성
    
    # 객체 생성 후 rfModel로 이름 지어줌
    rfModel = RandomForestClassifier() # >분류기 객체 만들어짐
    
    # windspeed data가 string이어야 rf 가능
    dataWindNot0['windspeed'] = dataWindNot0['windspeed'].astype("str")
    
    """
    wCol에 따라 풍속 예측하고자 => 풍속결정짓는 wCol 일반화해주는 fit()
    wCol -> 풍속 학습 -> 모델완성
    """
    rfModel.fit(dataWindNot0[wCol],dataWindNot0['windspeed'])
    # windspeed를 알고자, windspeed값을 wCol에 있는 것들로 학습
    
    # 학습한 모델로 풍속 0에 대한 데이터 예측
    preValue = rfModel.predict(X=dataWind0[wCol]) # X=dataWind0[wCol]: 입력 데이터
    print(preValue)
    
    predictWind0 = dataWind0
    predictWindNot0 = dataWindNot0
    
    predictWind0['windspeed'] = preValue
    
    data = predictWindNot0.append(predictWind0)
    data.reset_index(inplace=True)
    data.drop('index', inplace=True, axis=1)
    
    return data


train = predict_windspeed(train)
test = predict_windspeed(test)
```

![풍속예측값_rf결과](images/풍속예측값_rf결과.png)

* 시각화 통해서 데이터 확인

```python
fig,ax1 = plt.subplots()
plt.sca(ax1)
plt.xticks(rotation=30)
sns.countplot(data=train, x='windspeed', ax=ax1)
```

![시각화2](images/시각화2.png)

#### featrue selection

>자전거 데이터 분석
>
>=> count값 예측하는 것이 목표
>=> (???) -> count?(==어떤 feature 사용해서 count 예측할까?)
>
>가장 단순한 방법은 feature 하나씩 다 돌려서 성능 좋은 feature들로 모델 만들 수도 있음

>feature(변수)
>- 연속형 : temp, humi, wind, atemp
>- 범주형변수는 타입을 category로 변경해줘야 함

```python
type(train['season']) 
# > pandas.core.series.Series
train['season'].dtypes
# > dtype('int64')

"""
범주형변수 > category
"""
train['season'] = train['season'].astype('category')
test['season'] = test['season'].astype('category')

train['season'].dtype
# > CategoricalDtype(categories=[1, 2, 3, 4], ordered=False)
```

```python
feature_names = ['season', 'holiday', 'workingday', 'weather', 'temp',
                 'atemp', 'humidity', 'windspeed', 'year', 'hour', 'dayofweek']

"""
수치형 > 범주형으로 변환
바꿔야 할 변수 많아 for문으로 만들어 돌려주기
"""

c_f_n = ['season', 'holiday', 'workingday', 'weather', 'year', 'hour', 'dayofweek', 'month']

for v in c_f_n:
    train[v] = train[v].astype('category')
    test[v] = test[v].astype('category')
```

* 중요하다고 생각되는 변수만(=feature_names) 넣어준 것

```python
# 임의적으로 과정 생략하고 중요하다고 생각되는 변수만(=feature_names) 넣어준 것

xtrain = train[feature_names]
xtrain.shape # (10886, 11)

xtest = test[feature_names]
xtest.shape # (6493, 11)
```

```python
ytrain = train['count'] # 레이블(정답)
ytrain.shape # (10886,)
```



####  kaggle: bike sharing demand 함수 구현

![함수식](images/함수식.png)

```python
def rmsle(predicted_value, actual_value):
    # 넘파이 배열로의 변환
    predicted_value = np.array(predicted_value)
    actual_value = np.array(actual_value)
    log_predict = np.log(predicted_value + 1)
    log_actual = np.log(actual_value + 1)
    
    diff = log_predict - log_actual
    diff = np.square(diff) # 넘파이, 제곱하는 함수로 diff ** 2와 같음
    mean_diff = diff.mean()
    score = np.sqrt(mean_diff)
    return score

from sklearn.metrics import make_scorer
rmsle_scorer = make_scorer(rmsle)
rmsle_scorer
# > make_scorer(rmsle)
```



#### cross validiation

> k-fold cross validiation(교차검증)
> k: fold의 개수(핸즈온 머신러닝 127p)
>
> 전체 데이터 나누기 > 나뉜 데이터를 'fold(폴드)'라고 부름 
>
> > fold 만들 데이터 뽑을 때 랜덤하게 아무거나 뽑아서 만드는 것이 좋음

> ex) data : 400개
> 1 2 3 4 : 4개의 폴드 => 4-fold cross validiation
> => train용으로 모델 만든 후 test용으로 test해서 모델 평가
> 1 2 3 : train, 4 : test => 모델평가(80)
> 1 2 4 : train, 3 : test => 모델평가(70%)
> 1 3 4 : train, 2 : test => 모델평가(80%)
> 2 3 4 : train, 1 : test => 모델평가(70%)
>
> > 사용하는 폴드에 따라 모델과 모델평가가 바뀜

##### kfold

> kfold = train data안에서 데이터 나눠서 train, test 작업 후에 평균 test값(=validation)인 검증값 나옴

> train data(10000건) => 10-fold 
>
> > 1000개씩 10개로 나눠짐: 이 안에서 9개로 모델 만들고 1 폴드로 test >> 10번 폴드가 test로 올때까지 반복해서 전체 평균 구함(ex.90%)
> >
> > > train data에 대한 정확도: 90% == validation
> > > test data는 손도 안 댄 상태
>

> kfold train data에서 검증이 필요한 이유
>
> : 모델 만드는데 있어서 빠진 것은 없는지, 변수 선택은 잘 되었는지 확인하는 과정
> > train data에는 레이블이 담겨있어 검증하고 평균 구할 수 있어
> > test data는 레이블 없어 검증 x, 제출해야 알 수 있음
>
>
> test data(6000건)

```python
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
```

```python
kfold = KFold(n_splits=10, shuffle=True, random_state=42) 
# n_splits=10: 10개의 폴드로 나누기
```

```python
# 랜덤포레스트로 예측: 연속형 값 예측하려는 것

"""
n_estimators=: 나무의 개수로 생각하면 된다. 랜덤 포레스트를 형성할 나무 몇 그루로 하겠냐
n_jobs: core의 개수, 최적값이 -1
random_state: 나무를 랜덤하게 만들기 위해 주는 옵션. 많은 경우의 수로 만들어질 수 있는 나무들 중에 랜덤하게 뽑는 것, *동일한 값을 줘서 모델 비교해줘야 함
"""
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42) 
```

```python
%time score = cross_val_score(model, xtrain, ytrain, cv=kfold, scoring=rmsle_scorer)
# %time: 결과나오기까지 결리는 시간도 출력

# print(score)
print(score.mean())
# > Wall time: 14.6 s
#   0.33096917006785725
```

```python
model.fit(xtrain, ytrain)
```

![모델돌리기](images/모델돌리기-1579595021241.png)

```python
prediction = model.predict(xtest)
prediction
# > array([ 12.66,   3.57,   2.93, ..., 207.46,  62.82, 186.31])

prediction.shape
# > (6493,)
```



#### kaggle 제출

```python
submisson = pd.read_csv('bike-sharing-demand/sampleSubmission.csv')
submisson['count'] = prediction

submisson
```

![결과 제출](images/결과 제출.png)